{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffab26c9-4a2c-4079-8fe7-a4e3d5902170",
   "metadata": {},
   "source": [
    "This is a script that scrapes google scholar for all that juicy data.\n",
    "\n",
    "First, it sets up a URL given a search topic you provide. It then searches for court cases with that topic\n",
    "and filters only the links that are actual court cases. It uses the request module for this.\n",
    "\n",
    "It then stores all those links in a list. It goes through those links and gets the HTML page of the court case.\n",
    "Next, it makes use of BeautifulSoup, which has a built in way to remove all the HTML garbage, and gives us just text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04555810-66ee-47e7-b8ad-91fd32a122c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ea9656-918b-4284-a079-11c4a40e5ca5",
   "metadata": {},
   "source": [
    "Tricks the webpage into thinking i'm just an innocent chrome user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "359b024e-10f7-411a-99cf-71df27a4d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49fa7cc5-da60-4089-be4a-d0ff0c08f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the name for the text file\n",
    "def SimplifyCaseTitle(case_title):\n",
    "    simplified_title = re.sub(r',\\s\\d+.*$', '', case_title)\n",
    "    if len(simplified_title) > 128:\n",
    "        return simplified_title[:128-3] + '..'\n",
    "    else:\n",
    "        return simplified_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf361fd-8266-4045-878a-36a610ebfd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove things like page breaks\n",
    "def RemoveGarbage(DirtyString):\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', DirtyString)\n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd50d2bc-4c66-4918-88ff-3e5dedb3d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send text to a text document in Output\n",
    "def OutputText(text):\n",
    "    FileName = SimplifyCaseTitle(text[0:300]) + \".txt\"\n",
    "    FileName = FileName.replace(\"\\\\\", \"\")\n",
    "    outputFolderPath = os.path.join(os.getcwd(), 'Output')\n",
    "    if not os.path.exists(outputFolderPath):\n",
    "        os.makedirs(outputFolderPath)\n",
    "    filePath = os.path.join(outputFolderPath, FileName)\n",
    "    with open(filePath, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da848e66-989c-48d8-8e57-149bf11a9814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a page num and search query and gives you a good URL\n",
    "def GenerateBaseURL(SearchQuery, Page):\n",
    "    SearchQuery = SearchQuery.replace(' ', '+')\n",
    "    StartOn = (Page - 1) * 10\n",
    "    return ScholarURL + PreStart + str(StartOn) + PreQuery + SearchQuery + PostQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dc4b50f-5470-45ba-908a-52d0f96cb98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find links on page and put them into a nice little list\n",
    "def GetLinksFromPage(ParsedHTML):\n",
    "    PageLinks = set()\n",
    "    for link in ParsedHTML.find_all('a', href=True):\n",
    "        full_url = urljoin(ScholarURL, link['href'])\n",
    "        if urlparse(full_url).netloc == urlparse(ScholarURL).netloc:\n",
    "            lowerURL = full_url.lower()\n",
    "            IsGoodPage = 'scholar_case?case=' in lowerURL\n",
    "            if IsGoodPage:\n",
    "                PageLinks.add(full_url)\n",
    "    return PageLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7030f645-08b4-43b4-bf04-2f5a51a98d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific info for google scholar\n",
    "ScholarURL = \"https://scholar.google.com\"\n",
    "PreStart = \"/scholar?start=\"\n",
    "PreQuery = \"&q=\"\n",
    "PostQuery = \"&hl=en&as_sdt=8000006\"\n",
    "\n",
    "# What you're searching for on the website\n",
    "SearchQuery = \"Microsoft\"\n",
    "\n",
    "# How many pages to parse? 1 page is 10 text documents.\n",
    "# Too much of this gets me blocked. good thing i have a vpn on my laptop\n",
    "HowManyPagesToParse = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bb59923-7455-4d11-a0b1-42c2e177f50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE URL: https://scholar.google.com/scholar?start=0&q=Microsoft&hl=en&as_sdt=8000006\n",
      "(1/60) US v. Microsoft Corp..txt\n",
      "(2/60) Odom v. Microsoft Corp..txt\n",
      "(3/60) US v. Microsoft Corp..txt\n",
      "(4/60) US v. Microsoft Corp..txt\n",
      "(5/60) US v. Microsoft Corp..txt\n",
      "(6/60) Dickson v. Microsoft Corp..txt\n",
      "(7/60) Vizcaino v. Microsoft Corp..txt\n",
      "(8/60) Microsoft Corp. v. Baker.txt\n",
      "(9/60) US v. Microsoft Corp..txt\n",
      "(10/60) US v. Microsoft Corp..txt\n",
      "BASE URL: https://scholar.google.com/scholar?start=10&q=Microsoft&hl=en&as_sdt=8000006\n",
      "(11/60) Microsoft Corp. v. i4i Ltd. Partnership.txt\n",
      "(12/60) Vizcaino v. Microsoft Corp..txt\n",
      "(13/60) i4i Ltd. Partnership v. Microsoft Corp..txt\n",
      "(14/60) ENFISH, LLC v. Microsoft Corp..txt\n",
      "(15/60) Johnson v. Microsoft Corp..txt\n",
      "(16/60) Massachusetts v. Microsoft Corp..txt\n",
      "(17/60) Vizcaino v. Microsoft Corp..txt\n",
      "(18/60) Amado v. Microsoft Corp..txt\n",
      "(19/60) Microsoft Corp. v. Motorola, Inc..txt\n",
      "(20/60) Microsoft Corp. v. AT & T CORP..txt\n",
      "BASE URL: https://scholar.google.com/scholar?start=20&q=Microsoft&hl=en&as_sdt=8000006\n",
      "(21/60) US v. Microsoft Corp..txt\n",
      "(22/60) Davis v. Microsoft Corp..txt\n",
      "(23/60) Deiter v. Microsoft Corp..txt\n",
      "(24/60) US v. Microsoft Corp..txt\n",
      "(25/60) Kloth v. Microsoft Corp..txt\n",
      "(26/60) Morrow v. Microsoft Corp..txt\n",
      "(27/60) Uniloc USA, Inc. v. Microsoft Corp..txt\n",
      "(28/60) Apple Computer, Inc. v. Microsoft Corp..txt\n",
      "(29/60) Caspi v. Microsoft Network, LLC.txt\n",
      "(30/60) Reiffin v. Microsoft Corp..txt\n",
      "BASE URL: https://scholar.google.com/scholar?start=30&q=Microsoft&hl=en&as_sdt=8000006\n",
      "(31/60) Microsoft Corp. v. Motorola, Inc..txt\n",
      "(32/60) In re Microsoft Corporation Antitrust Litigation.txt\n",
      "(33/60) Hoffer v. Microsoft Corp..txt\n",
      "(34/60) US v. Microsoft Corp..txt\n",
      "(35/60) US v. Microsoft Corp..txt\n",
      "(36/60) Moore v. Microsoft Corporation.txt\n",
      "(37/60) In re Microsoft Corp..txt\n",
      "(38/60) Reiffin v. Microsoft Corp..txt\n",
      "(39/60) Comes v. Microsoft Corp..txt\n",
      "(40/60) In re Microsoft Corp..txt\n",
      "BASE URL: https://scholar.google.com/scholar?start=40&q=Microsoft&hl=en&as_sdt=8000006\n",
      "(41/60) Eolas Technologies Inc. v. Microsoft Corp..txt\n",
      "(42/60) Sun Microsystems, Inc. v. Microsoft Corp..txt\n",
      "(43/60) Novell, Inc. v. Microsoft Corp..txt\n",
      "(44/60) .txt\n",
      "(45/60) .txt\n",
      "(46/60) .txt\n",
      "(47/60) .txt\n",
      "(48/60) .txt\n",
      "(49/60) .txt\n",
      "(50/60) .txt\n",
      "BASE URL: https://scholar.google.com/scholar?start=50&q=Microsoft&hl=en&as_sdt=8000006\n"
     ]
    }
   ],
   "source": [
    "TotalDocuments = 10 * HowManyPagesToParse\n",
    "CurrentDocument = 1\n",
    "for i in range(HowManyPagesToParse):\n",
    "    # Go through the search results and find every webpage\n",
    "    ParseTestURL = GenerateBaseURL(SearchQuery, i + 1)\n",
    "    BaseSearchPage = requests.get(ParseTestURL, headers=headers)\n",
    "    BaseSearchParse = BeautifulSoup(BaseSearchPage.text, 'html.parser')\n",
    "    print(\"BASE URL: \" + ParseTestURL)\n",
    "    URLS = GetLinksFromPage(BaseSearchParse)\n",
    "\n",
    "    for url in URLS:\n",
    "\n",
    "        # So the overlords at google don't come kill me\n",
    "        time.sleep(random.randint(1000, 4000) / 1000)\n",
    "        \n",
    "        # Go through every link on the search results, get text, and dump it into a file in the 'Output' folder\n",
    "        Requested = requests.get(url, headers=headers)\n",
    "        Parsed = BeautifulSoup(Requested.text, 'html.parser')\n",
    "        for ScriptOrStyle in Parsed([\"script\", \"style\"]):\n",
    "            ScriptOrStyle.decompose()\n",
    "        TextFragments = [Element.get_text() for Element in Parsed.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])]\n",
    "        CleanText = ' '.join(TextFragment.strip() for TextFragment in TextFragments)\n",
    "        CleanText = RemoveGarbage(CleanText)\n",
    "        print(\"(\" + str(CurrentDocument) + \"/\" + str(TotalDocuments) + \") \" + SimplifyCaseTitle(CleanText[0:300]) + \".txt\")\n",
    "        OutputText(CleanText)\n",
    "        CurrentDocument += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e1523-4c2c-4821-ae8a-6c7c3d9389b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
